{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KnyazevAV/hangman/blob/master/%D0%94%D0%B8%D0%BF%D0%BB%D0%BE%D0%BC%D0%BD%D1%8B%D0%B9_%D0%BF%D1%80%D0%BE%D0%B5%D0%BA%D1%82_%D0%A3%D0%BD%D0%B8%D0%B2%D0%B5%D1%80%D1%81%D0%B8%D1%82%D0%B5%D1%82_%D0%98%D1%81%D0%BA%D1%83%D1%81%D1%82%D0%B2%D0%B5%D0%BD%D0%BD%D0%BE%D0%B3%D0%BE_%D0%98%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82%D0%B0_(%D0%9A%D0%BD%D1%8F%D0%B7%D0%B5%D0%B2_%D0%90_)_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Нейросеть для всех испытуемых c разбивкой на 1 секунду и перемешиванием CNN+LSTM Tahn"
      ],
      "metadata": {
        "id": "OUO66TPG-94P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9C-mTbFIpBEa"
      },
      "outputs": [],
      "source": [
        "import numpy as np #Библиотека работы с массивами\n",
        "import pandas as pd # Библиотека для работы с базами\n",
        "import random\n",
        "\n",
        "from tensorflow.keras.models import Sequential, Model # \n",
        "from tensorflow.keras.layers import concatenate, Input, Dense, Dropout, BatchNormalization, LSTM, Flatten, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Reshape, Bidirectional #\n",
        "from tensorflow.keras import utils #Используем для to_categoricall\n",
        "from tensorflow.keras.optimizers import Adam,Adadelta,SGD,Adagrad,RMSprop #\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence #\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences #\n",
        "from tensorflow.keras.callbacks import LambdaCallback, LearningRateScheduler # подключаем колбэки\n",
        "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator # для генерации выборки временных рядов\n",
        "import tensorflow as tf\n",
        "from contextlib import suppress\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler #Нормировщики\n",
        "from sklearn.model_selection import train_test_split # Для разбивки на выборки\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error #\n",
        "import os\n",
        "import sys\n",
        "import matplotlib.pyplot as plt #Отрисовка графиков\n",
        "\n",
        "from statistics import mean "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiPxnCYqpJ4S",
        "outputId": "9b876169-3c88-40d7-9829-2bc7f0c44d1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KG_-LZRkpOGc"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/My Drive/temp/fnirs_dataset'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHrDg3YvpQ6U"
      },
      "outputs": [],
      "source": [
        "#функция загрузки данных в один dataframe\n",
        "def data_load(path):\n",
        "  frames_temp = []\n",
        "  #try:\n",
        "  for i in range(100):\n",
        "      with suppress(FileNotFoundError):\n",
        "        i += 1\n",
        "        df_temp = pd.read_csv(path + '/sub_{}.csv'.format(i))\n",
        "        frames_temp.append(df_temp)\n",
        "  #except FileNotFoundError:\n",
        "    #print('такого номера нет:', i)\n",
        "  df_full = pd.concat(frames_temp, axis=0, join='outer', ignore_index=True, keys=None)\n",
        "  return df_full"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akEXsKlnpTsX"
      },
      "outputs": [],
      "source": [
        "df_full = data_load('/content/drive/My Drive/temp/fnirs_dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZi1rPKlpUlB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "3384116c-cbb6-4b52-8fec-49b7d9f1926a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          AB_I_O  AB_PHI_O   AB_I_DO  AB_PHI_DO    CD_I_O   CD_PHI_O  \\\n",
              "0      -0.198291  0.335677 -0.560790  -0.056042  0.460231   0.271119   \n",
              "1      -0.195651  0.297210 -0.580712  -0.032170  0.524553   0.208284   \n",
              "2      -0.192790  0.275041 -0.600446  -0.012370  0.585149   0.162781   \n",
              "3      -0.189943  0.271573 -0.619751   0.002192  0.641092   0.133816   \n",
              "4      -0.187401  0.288043 -0.638379   0.010818  0.691434   0.119983   \n",
              "...          ...       ...       ...        ...       ...        ...   \n",
              "422587  3.369915  0.973203 -1.159197   0.057686  2.524704  45.670449   \n",
              "422588  3.365014  1.040236 -1.161509   0.013463  2.514158  43.258719   \n",
              "422589  3.358334  1.105486 -1.163388  -0.026700  2.507242  40.041532   \n",
              "422590  3.350465  1.165158 -1.165147  -0.061719  2.504038  35.925716   \n",
              "422591  3.341976  1.216122 -1.167104  -0.091096  2.504169  30.856358   \n",
              "\n",
              "         CD_I_DO  CD_PHI_DO  label  \n",
              "0      -0.645892   0.198804      0  \n",
              "1      -0.681370   0.202136      0  \n",
              "2      -0.716632   0.194758      0  \n",
              "3      -0.750998   0.176938      0  \n",
              "4      -0.783748   0.149429      0  \n",
              "...          ...        ...    ...  \n",
              "422587 -1.088880 -60.652208      2  \n",
              "422588 -1.090080 -57.468358      2  \n",
              "422589 -1.091969 -53.234109      2  \n",
              "422590 -1.094843 -47.821654      2  \n",
              "422591 -1.098938 -41.152765      2  \n",
              "\n",
              "[422592 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fd66fb17-5b9f-4fad-89ba-d325bdc2642b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AB_I_O</th>\n",
              "      <th>AB_PHI_O</th>\n",
              "      <th>AB_I_DO</th>\n",
              "      <th>AB_PHI_DO</th>\n",
              "      <th>CD_I_O</th>\n",
              "      <th>CD_PHI_O</th>\n",
              "      <th>CD_I_DO</th>\n",
              "      <th>CD_PHI_DO</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.198291</td>\n",
              "      <td>0.335677</td>\n",
              "      <td>-0.560790</td>\n",
              "      <td>-0.056042</td>\n",
              "      <td>0.460231</td>\n",
              "      <td>0.271119</td>\n",
              "      <td>-0.645892</td>\n",
              "      <td>0.198804</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.195651</td>\n",
              "      <td>0.297210</td>\n",
              "      <td>-0.580712</td>\n",
              "      <td>-0.032170</td>\n",
              "      <td>0.524553</td>\n",
              "      <td>0.208284</td>\n",
              "      <td>-0.681370</td>\n",
              "      <td>0.202136</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.192790</td>\n",
              "      <td>0.275041</td>\n",
              "      <td>-0.600446</td>\n",
              "      <td>-0.012370</td>\n",
              "      <td>0.585149</td>\n",
              "      <td>0.162781</td>\n",
              "      <td>-0.716632</td>\n",
              "      <td>0.194758</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.189943</td>\n",
              "      <td>0.271573</td>\n",
              "      <td>-0.619751</td>\n",
              "      <td>0.002192</td>\n",
              "      <td>0.641092</td>\n",
              "      <td>0.133816</td>\n",
              "      <td>-0.750998</td>\n",
              "      <td>0.176938</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.187401</td>\n",
              "      <td>0.288043</td>\n",
              "      <td>-0.638379</td>\n",
              "      <td>0.010818</td>\n",
              "      <td>0.691434</td>\n",
              "      <td>0.119983</td>\n",
              "      <td>-0.783748</td>\n",
              "      <td>0.149429</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>422587</th>\n",
              "      <td>3.369915</td>\n",
              "      <td>0.973203</td>\n",
              "      <td>-1.159197</td>\n",
              "      <td>0.057686</td>\n",
              "      <td>2.524704</td>\n",
              "      <td>45.670449</td>\n",
              "      <td>-1.088880</td>\n",
              "      <td>-60.652208</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>422588</th>\n",
              "      <td>3.365014</td>\n",
              "      <td>1.040236</td>\n",
              "      <td>-1.161509</td>\n",
              "      <td>0.013463</td>\n",
              "      <td>2.514158</td>\n",
              "      <td>43.258719</td>\n",
              "      <td>-1.090080</td>\n",
              "      <td>-57.468358</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>422589</th>\n",
              "      <td>3.358334</td>\n",
              "      <td>1.105486</td>\n",
              "      <td>-1.163388</td>\n",
              "      <td>-0.026700</td>\n",
              "      <td>2.507242</td>\n",
              "      <td>40.041532</td>\n",
              "      <td>-1.091969</td>\n",
              "      <td>-53.234109</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>422590</th>\n",
              "      <td>3.350465</td>\n",
              "      <td>1.165158</td>\n",
              "      <td>-1.165147</td>\n",
              "      <td>-0.061719</td>\n",
              "      <td>2.504038</td>\n",
              "      <td>35.925716</td>\n",
              "      <td>-1.094843</td>\n",
              "      <td>-47.821654</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>422591</th>\n",
              "      <td>3.341976</td>\n",
              "      <td>1.216122</td>\n",
              "      <td>-1.167104</td>\n",
              "      <td>-0.091096</td>\n",
              "      <td>2.504169</td>\n",
              "      <td>30.856358</td>\n",
              "      <td>-1.098938</td>\n",
              "      <td>-41.152765</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>422592 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd66fb17-5b9f-4fad-89ba-d325bdc2642b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fd66fb17-5b9f-4fad-89ba-d325bdc2642b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fd66fb17-5b9f-4fad-89ba-d325bdc2642b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df_full"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2V2tHdBpVzG"
      },
      "outputs": [],
      "source": [
        "#посмотрим, как выстроена парадигма исследования (как n-back задачи идут друг за другом)\n",
        "n_back_labels = []\n",
        "for i in range(len(df_full.label)):\n",
        "  if i == 0:\n",
        "    n_back_labels.append(df_full.label[i])\n",
        "    continue\n",
        "  if df_full.label[i] == df_full.label[i-1]:\n",
        "    continue\n",
        "  else:\n",
        "    n_back_labels.append(df_full.label[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucOcsOo2pnPA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21a86d67-4d72-4d63-a121-1055393ce04a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "кол-во задач: 992\n",
            "кол-во отсчетов на 1 задачу: 426.0\n"
          ]
        }
      ],
      "source": [
        "print('кол-во задач:', len(n_back_labels))\n",
        "print('кол-во отсчетов на 1 задачу:', len(df_full)/len(n_back_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCZNQIO0poDp"
      },
      "source": [
        "Попробуем сделать разбивку на 6 измерений, что примерно эквивалентно 1 секунде"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "напишем функцию подготовки xTrain и yTrain"
      ],
      "metadata": {
        "id": "8FLzc8keWtpH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def drop_dataset(dataset, xLen):\n",
        "\n",
        "  #соберем данные в список\n",
        "  l_Train = []\n",
        "\n",
        "  i = 0\n",
        "  while i <= len(dataset):\n",
        "    l_Train.append(dataset[i:i+xLen])\n",
        "    i += xLen\n",
        "\n",
        "  #удалим последний \"пустой\" элемент списка\n",
        "  l_Train.pop(int(len(dataset)/xLen))  \n",
        "  \n",
        "  #перемешаем список l_xTrain\n",
        "  random.shuffle(l_Train)\n",
        "\n",
        "  #сформируем xTrain и yTrain\n",
        "  xTrain_list = []\n",
        "  yTrain_list = []\n",
        "  for i in range(len(l_Train)):\n",
        "    xTrain_list.append(l_Train[i][['AB_I_O', 'AB_PHI_O',\t'AB_I_DO',\t'AB_PHI_DO',\t'CD_I_O',\t'CD_PHI_O',\t'CD_I_DO',\t'CD_PHI_DO']])\n",
        "    yTrain_list.append(l_Train[i][['label']])\n",
        "\n",
        "\n",
        "  xTrain = np.array(xTrain_list)\n",
        "\n",
        "  #доделаем yTrain\n",
        "  l1 = []\n",
        "  l2 = []\n",
        "  l3 = []\n",
        "  for i in range(len(yTrain_list)):\n",
        "\n",
        "    #l1.clear()\n",
        "    l1 = []\n",
        "    for j in range(len(yTrain_list[i])):\n",
        "\n",
        "      l1.append(int(yTrain_list[i].iloc[j][0]))\n",
        "    l2.append(l1)\n",
        "\n",
        "\n",
        "  #сформируем список длинною xTrain со значениями номеров задач n-back\n",
        "  for i in range(len(l2)):\n",
        "    l3.append(mean(l2[i]))\n",
        "\n",
        "  yTrain = np.array( utils.to_categorical(l3, 4))\n",
        "\n",
        "  return xTrain, yTrain"
      ],
      "metadata": {
        "id": "btdRh6WtWxr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xTrain, yTrain = drop_dataset(df_full, 6)"
      ],
      "metadata": {
        "id": "6MkUGD9vXh_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xTrain.shape, yTrain.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7R9McDQaXqIq",
        "outputId": "a03e9269-7545-4257-966c-b3a75f61a377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((70432, 6, 8), (70432, 4))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Соберем заранее тестовую выборку"
      ],
      "metadata": {
        "id": "z8GTz28Gy9N_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#загрузим 1 датасет, на котором сеть не обучалась\n",
        "test_dataset = ('/content/drive/My Drive/temp/fnirs_dataset')\n",
        "df_test = data_load(test_dataset)\n",
        "xLen = 6\n",
        "xTest, yTest = drop_dataset(df_test, xLen)"
      ],
      "metadata": {
        "id": "yy7UTqv4zBWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WE_lAIqN3HAp"
      },
      "source": [
        "Напишем LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBv32bNx3JXe"
      },
      "outputs": [],
      "source": [
        "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "xLen = 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhLIabCX3Jdg",
        "outputId": "a7965b56-572a-4455-ab95-547fac353aac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "inputs = Input((xLen, 8))\n",
        "\n",
        "x = Conv1D(256, 3, strides=1, padding='same', activation='tanh')(inputs)\n",
        "x = Conv1D(128, 3, strides=1 ,padding='same', activation='tanh')(x)\n",
        "x = Conv1D(64, 3, strides=1, padding='same', activation='tanh')(x)\n",
        "x = Conv1D(32, 3, strides=1, padding='same', activation='tanh')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling1D()(x)\n",
        "\n",
        "x = LSTM(256, return_sequences=True)(inputs)\n",
        "x = BatchNormalization()(x)\n",
        "x = LSTM(128)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = tf.expand_dims(x, axis=-1)\n",
        "x = LSTM(64)(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "\n",
        "x = Dense(256, activation='tanh')(x)\n",
        "x = Dense(128, activation='tanh')(x)\n",
        "x = Dense(64, activation='tanh')(x)\n",
        "x = Dense(32, activation='tanh')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "output = Dense(4, activation='softmax')(x)\n",
        "\n",
        "model_CNN_LSTM = Model(inputs, output)\n",
        "model_CNN_LSTM.compile(loss=loss_fn, optimizer=Adam(lr=1e-4), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VK3nyFFM35yg",
        "outputId": "d8270955-5084-4346-f5ed-d70ff835984c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 6, 8)]            0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 6, 256)            271360    \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 6, 256)           1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 128)               197120    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " tf.expand_dims (TFOpLambda)  (None, 128, 1)           0         \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 64)                16896     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 64)               256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               16640     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 4)                 132       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 547,172\n",
            "Trainable params: 546,276\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_CNN_LSTM.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ajPBcKT394v",
        "outputId": "4ffba9e3-7c6e-4f17-de6d-16d067f9448a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "991/991 [==============================] - 25s 15ms/step - loss: 1.3588 - accuracy: 0.3209 - val_loss: 1.3403 - val_accuracy: 0.3392\n",
            "Epoch 2/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.3364 - accuracy: 0.3477 - val_loss: 1.3245 - val_accuracy: 0.3582\n",
            "Epoch 3/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.3234 - accuracy: 0.3623 - val_loss: 1.3102 - val_accuracy: 0.3751\n",
            "Epoch 4/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.3107 - accuracy: 0.3739 - val_loss: 1.3007 - val_accuracy: 0.3795\n",
            "Epoch 5/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.3016 - accuracy: 0.3810 - val_loss: 1.2859 - val_accuracy: 0.3903\n",
            "Epoch 6/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.2925 - accuracy: 0.3906 - val_loss: 1.2850 - val_accuracy: 0.3878\n",
            "Epoch 7/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.2819 - accuracy: 0.3977 - val_loss: 1.2765 - val_accuracy: 0.3971\n",
            "Epoch 8/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.2743 - accuracy: 0.4015 - val_loss: 1.2715 - val_accuracy: 0.3940\n",
            "Epoch 9/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.2673 - accuracy: 0.4085 - val_loss: 1.2578 - val_accuracy: 0.4093\n",
            "Epoch 10/50\n",
            "991/991 [==============================] - 14s 14ms/step - loss: 1.2603 - accuracy: 0.4129 - val_loss: 1.2538 - val_accuracy: 0.4096\n",
            "Epoch 11/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.2532 - accuracy: 0.4173 - val_loss: 1.2433 - val_accuracy: 0.4174\n",
            "Epoch 12/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.2459 - accuracy: 0.4231 - val_loss: 1.2412 - val_accuracy: 0.4202\n",
            "Epoch 13/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.2387 - accuracy: 0.4277 - val_loss: 1.2394 - val_accuracy: 0.4239\n",
            "Epoch 14/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.2355 - accuracy: 0.4318 - val_loss: 1.2320 - val_accuracy: 0.4255\n",
            "Epoch 15/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.2291 - accuracy: 0.4340 - val_loss: 1.2252 - val_accuracy: 0.4338\n",
            "Epoch 16/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.2225 - accuracy: 0.4405 - val_loss: 1.2278 - val_accuracy: 0.4316\n",
            "Epoch 17/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.2193 - accuracy: 0.4409 - val_loss: 1.2191 - val_accuracy: 0.4387\n",
            "Epoch 18/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.2132 - accuracy: 0.4435 - val_loss: 1.2214 - val_accuracy: 0.4280\n",
            "Epoch 19/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.2077 - accuracy: 0.4460 - val_loss: 1.2216 - val_accuracy: 0.4300\n",
            "Epoch 20/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.2027 - accuracy: 0.4491 - val_loss: 1.2081 - val_accuracy: 0.4415\n",
            "Epoch 21/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.1966 - accuracy: 0.4565 - val_loss: 1.2377 - val_accuracy: 0.4205\n",
            "Epoch 22/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.1933 - accuracy: 0.4562 - val_loss: 1.2152 - val_accuracy: 0.4323\n",
            "Epoch 23/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.1883 - accuracy: 0.4581 - val_loss: 1.2018 - val_accuracy: 0.4441\n",
            "Epoch 24/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.1839 - accuracy: 0.4636 - val_loss: 1.1942 - val_accuracy: 0.4466\n",
            "Epoch 25/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.1775 - accuracy: 0.4671 - val_loss: 1.1908 - val_accuracy: 0.4503\n",
            "Epoch 26/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.1735 - accuracy: 0.4692 - val_loss: 1.1863 - val_accuracy: 0.4526\n",
            "Epoch 27/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.1708 - accuracy: 0.4703 - val_loss: 1.1883 - val_accuracy: 0.4512\n",
            "Epoch 28/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.1672 - accuracy: 0.4736 - val_loss: 1.2061 - val_accuracy: 0.4378\n",
            "Epoch 29/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.1608 - accuracy: 0.4763 - val_loss: 1.1833 - val_accuracy: 0.4506\n",
            "Epoch 30/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.1575 - accuracy: 0.4785 - val_loss: 1.1815 - val_accuracy: 0.4543\n",
            "Epoch 31/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.1534 - accuracy: 0.4811 - val_loss: 1.1785 - val_accuracy: 0.4600\n",
            "Epoch 32/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.1522 - accuracy: 0.4802 - val_loss: 1.1778 - val_accuracy: 0.4564\n",
            "Epoch 33/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.1448 - accuracy: 0.4863 - val_loss: 1.1768 - val_accuracy: 0.4577\n",
            "Epoch 34/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.1426 - accuracy: 0.4880 - val_loss: 1.1694 - val_accuracy: 0.4625\n",
            "Epoch 35/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.1365 - accuracy: 0.4921 - val_loss: 1.1663 - val_accuracy: 0.4638\n",
            "Epoch 36/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.1344 - accuracy: 0.4925 - val_loss: 1.1729 - val_accuracy: 0.4638\n",
            "Epoch 37/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.1310 - accuracy: 0.4933 - val_loss: 1.1712 - val_accuracy: 0.4709\n",
            "Epoch 38/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.1258 - accuracy: 0.4967 - val_loss: 1.1710 - val_accuracy: 0.4600\n",
            "Epoch 39/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.1215 - accuracy: 0.5003 - val_loss: 1.1626 - val_accuracy: 0.4693\n",
            "Epoch 40/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.1195 - accuracy: 0.5010 - val_loss: 1.1632 - val_accuracy: 0.4719\n",
            "Epoch 41/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.1154 - accuracy: 0.5044 - val_loss: 1.1646 - val_accuracy: 0.4683\n",
            "Epoch 42/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.1092 - accuracy: 0.5071 - val_loss: 1.1584 - val_accuracy: 0.4746\n",
            "Epoch 43/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.1082 - accuracy: 0.5044 - val_loss: 1.1599 - val_accuracy: 0.4737\n",
            "Epoch 44/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.1035 - accuracy: 0.5058 - val_loss: 1.1611 - val_accuracy: 0.4683\n",
            "Epoch 45/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.0998 - accuracy: 0.5118 - val_loss: 1.1540 - val_accuracy: 0.4700\n",
            "Epoch 46/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.0996 - accuracy: 0.5129 - val_loss: 1.1519 - val_accuracy: 0.4760\n",
            "Epoch 47/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.0944 - accuracy: 0.5145 - val_loss: 1.1542 - val_accuracy: 0.4759\n",
            "Epoch 48/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.0911 - accuracy: 0.5171 - val_loss: 1.1466 - val_accuracy: 0.4783\n",
            "Epoch 49/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.0874 - accuracy: 0.5169 - val_loss: 1.1484 - val_accuracy: 0.4793\n",
            "Epoch 50/50\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.0835 - accuracy: 0.5233 - val_loss: 1.1531 - val_accuracy: 0.4752\n"
          ]
        }
      ],
      "source": [
        "history_CNN_LSTM = model_CNN_LSTM.fit(xTrain, yTrain, epochs=50, batch_size=64, verbose=1, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_CNN_LSTM.evaluate(xTest, yTest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jroH6SW83bXm",
        "outputId": "581d78fb-7bac-45d0-ce0d-ef4dbaebe066"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2201/2201 [==============================] - 14s 6ms/step - loss: 1.0193 - accuracy: 0.5519\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0193222761154175, 0.5518798232078552]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_CNN_LSTM = model_CNN_LSTM.fit(xTrain, yTrain, epochs=150, batch_size=64, verbose=1, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiNhH6UEoUTe",
        "outputId": "a5759a6f-fb4a-4e87-a56d-528306b7bb07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.0783 - accuracy: 0.5229 - val_loss: 1.1784 - val_accuracy: 0.4611\n",
            "Epoch 2/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.0775 - accuracy: 0.5224 - val_loss: 1.1443 - val_accuracy: 0.4827\n",
            "Epoch 3/150\n",
            "991/991 [==============================] - 14s 14ms/step - loss: 1.0720 - accuracy: 0.5257 - val_loss: 1.1378 - val_accuracy: 0.4851\n",
            "Epoch 4/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.0702 - accuracy: 0.5282 - val_loss: 1.1973 - val_accuracy: 0.4629\n",
            "Epoch 5/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.0657 - accuracy: 0.5288 - val_loss: 1.1546 - val_accuracy: 0.4788\n",
            "Epoch 6/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.0606 - accuracy: 0.5331 - val_loss: 1.1423 - val_accuracy: 0.4813\n",
            "Epoch 7/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.0587 - accuracy: 0.5319 - val_loss: 1.1574 - val_accuracy: 0.4813\n",
            "Epoch 8/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.0534 - accuracy: 0.5352 - val_loss: 1.1365 - val_accuracy: 0.4902\n",
            "Epoch 9/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.0519 - accuracy: 0.5358 - val_loss: 1.1536 - val_accuracy: 0.4847\n",
            "Epoch 10/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.0479 - accuracy: 0.5405 - val_loss: 1.1398 - val_accuracy: 0.4888\n",
            "Epoch 11/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.0470 - accuracy: 0.5424 - val_loss: 1.1434 - val_accuracy: 0.4865\n",
            "Epoch 12/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.0418 - accuracy: 0.5429 - val_loss: 1.1328 - val_accuracy: 0.4926\n",
            "Epoch 13/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.0405 - accuracy: 0.5449 - val_loss: 1.1530 - val_accuracy: 0.4916\n",
            "Epoch 14/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.0362 - accuracy: 0.5434 - val_loss: 1.1403 - val_accuracy: 0.4894\n",
            "Epoch 15/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.0330 - accuracy: 0.5454 - val_loss: 1.1361 - val_accuracy: 0.4908\n",
            "Epoch 16/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.0276 - accuracy: 0.5504 - val_loss: 1.1313 - val_accuracy: 0.4886\n",
            "Epoch 17/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.0254 - accuracy: 0.5511 - val_loss: 1.1361 - val_accuracy: 0.4908\n",
            "Epoch 18/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.0225 - accuracy: 0.5540 - val_loss: 1.1279 - val_accuracy: 0.4922\n",
            "Epoch 19/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.0199 - accuracy: 0.5538 - val_loss: 1.1279 - val_accuracy: 0.4930\n",
            "Epoch 20/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.0157 - accuracy: 0.5559 - val_loss: 1.1407 - val_accuracy: 0.4938\n",
            "Epoch 21/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.0140 - accuracy: 0.5544 - val_loss: 1.1334 - val_accuracy: 0.4966\n",
            "Epoch 22/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.0099 - accuracy: 0.5595 - val_loss: 1.1298 - val_accuracy: 0.4932\n",
            "Epoch 23/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.0089 - accuracy: 0.5585 - val_loss: 1.1442 - val_accuracy: 0.4970\n",
            "Epoch 24/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.0042 - accuracy: 0.5610 - val_loss: 1.1306 - val_accuracy: 0.5011\n",
            "Epoch 25/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 1.0003 - accuracy: 0.5618 - val_loss: 1.1245 - val_accuracy: 0.4943\n",
            "Epoch 26/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.9964 - accuracy: 0.5641 - val_loss: 1.1387 - val_accuracy: 0.4947\n",
            "Epoch 27/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.9959 - accuracy: 0.5653 - val_loss: 1.1283 - val_accuracy: 0.5038\n",
            "Epoch 28/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.9904 - accuracy: 0.5704 - val_loss: 1.1316 - val_accuracy: 0.5004\n",
            "Epoch 29/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.9871 - accuracy: 0.5704 - val_loss: 1.1386 - val_accuracy: 0.4987\n",
            "Epoch 30/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.9861 - accuracy: 0.5723 - val_loss: 1.1435 - val_accuracy: 0.4956\n",
            "Epoch 31/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.9829 - accuracy: 0.5726 - val_loss: 1.1352 - val_accuracy: 0.5031\n",
            "Epoch 32/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.9781 - accuracy: 0.5747 - val_loss: 1.1256 - val_accuracy: 0.5007\n",
            "Epoch 33/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.9751 - accuracy: 0.5765 - val_loss: 1.1160 - val_accuracy: 0.5054\n",
            "Epoch 34/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.9729 - accuracy: 0.5781 - val_loss: 1.1484 - val_accuracy: 0.4986\n",
            "Epoch 35/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.9674 - accuracy: 0.5792 - val_loss: 1.1402 - val_accuracy: 0.4970\n",
            "Epoch 36/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.9653 - accuracy: 0.5819 - val_loss: 1.1218 - val_accuracy: 0.5060\n",
            "Epoch 37/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.9617 - accuracy: 0.5835 - val_loss: 1.1469 - val_accuracy: 0.4987\n",
            "Epoch 38/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.9594 - accuracy: 0.5827 - val_loss: 1.1305 - val_accuracy: 0.5030\n",
            "Epoch 39/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.9592 - accuracy: 0.5840 - val_loss: 1.1297 - val_accuracy: 0.5013\n",
            "Epoch 40/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.9536 - accuracy: 0.5858 - val_loss: 1.1305 - val_accuracy: 0.5038\n",
            "Epoch 41/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.9513 - accuracy: 0.5881 - val_loss: 1.1217 - val_accuracy: 0.5064\n",
            "Epoch 42/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.9481 - accuracy: 0.5918 - val_loss: 1.1389 - val_accuracy: 0.5009\n",
            "Epoch 43/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.9457 - accuracy: 0.5923 - val_loss: 1.1626 - val_accuracy: 0.5009\n",
            "Epoch 44/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.9442 - accuracy: 0.5919 - val_loss: 1.1250 - val_accuracy: 0.5149\n",
            "Epoch 45/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.9384 - accuracy: 0.5958 - val_loss: 1.1161 - val_accuracy: 0.5112\n",
            "Epoch 46/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.9369 - accuracy: 0.5942 - val_loss: 1.1294 - val_accuracy: 0.5112\n",
            "Epoch 47/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.9342 - accuracy: 0.5963 - val_loss: 1.1269 - val_accuracy: 0.5084\n",
            "Epoch 48/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.9313 - accuracy: 0.5974 - val_loss: 1.1171 - val_accuracy: 0.5194\n",
            "Epoch 49/150\n",
            "991/991 [==============================] - 14s 14ms/step - loss: 0.9240 - accuracy: 0.6042 - val_loss: 1.1308 - val_accuracy: 0.5106\n",
            "Epoch 50/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.9254 - accuracy: 0.6011 - val_loss: 1.1452 - val_accuracy: 0.5142\n",
            "Epoch 51/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.9179 - accuracy: 0.6045 - val_loss: 1.1231 - val_accuracy: 0.5160\n",
            "Epoch 52/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.9208 - accuracy: 0.6050 - val_loss: 1.1335 - val_accuracy: 0.5094\n",
            "Epoch 53/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.9111 - accuracy: 0.6083 - val_loss: 1.1212 - val_accuracy: 0.5187\n",
            "Epoch 54/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.9118 - accuracy: 0.6075 - val_loss: 1.1286 - val_accuracy: 0.5131\n",
            "Epoch 55/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.9063 - accuracy: 0.6104 - val_loss: 1.1330 - val_accuracy: 0.5146\n",
            "Epoch 56/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.9044 - accuracy: 0.6120 - val_loss: 1.1167 - val_accuracy: 0.5185\n",
            "Epoch 57/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.9023 - accuracy: 0.6120 - val_loss: 1.1409 - val_accuracy: 0.5139\n",
            "Epoch 58/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.9010 - accuracy: 0.6120 - val_loss: 1.1323 - val_accuracy: 0.5214\n",
            "Epoch 59/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.8982 - accuracy: 0.6151 - val_loss: 1.1399 - val_accuracy: 0.5074\n",
            "Epoch 60/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.8896 - accuracy: 0.6196 - val_loss: 1.1388 - val_accuracy: 0.5187\n",
            "Epoch 61/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.8907 - accuracy: 0.6198 - val_loss: 1.1201 - val_accuracy: 0.5190\n",
            "Epoch 62/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.8888 - accuracy: 0.6190 - val_loss: 1.1365 - val_accuracy: 0.5170\n",
            "Epoch 63/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.8823 - accuracy: 0.6232 - val_loss: 1.1379 - val_accuracy: 0.5153\n",
            "Epoch 64/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.8817 - accuracy: 0.6223 - val_loss: 1.1352 - val_accuracy: 0.5212\n",
            "Epoch 65/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.8805 - accuracy: 0.6244 - val_loss: 1.1361 - val_accuracy: 0.5219\n",
            "Epoch 66/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.8760 - accuracy: 0.6258 - val_loss: 1.1418 - val_accuracy: 0.5224\n",
            "Epoch 67/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.8745 - accuracy: 0.6274 - val_loss: 1.1295 - val_accuracy: 0.5213\n",
            "Epoch 68/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.8683 - accuracy: 0.6297 - val_loss: 1.1384 - val_accuracy: 0.5170\n",
            "Epoch 69/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.8677 - accuracy: 0.6305 - val_loss: 1.1378 - val_accuracy: 0.5169\n",
            "Epoch 70/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.8666 - accuracy: 0.6313 - val_loss: 1.1421 - val_accuracy: 0.5229\n",
            "Epoch 71/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.8606 - accuracy: 0.6331 - val_loss: 1.1403 - val_accuracy: 0.5209\n",
            "Epoch 72/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.8590 - accuracy: 0.6335 - val_loss: 1.1580 - val_accuracy: 0.5179\n",
            "Epoch 73/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.8541 - accuracy: 0.6372 - val_loss: 1.1479 - val_accuracy: 0.5128\n",
            "Epoch 74/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.8514 - accuracy: 0.6361 - val_loss: 1.1317 - val_accuracy: 0.5182\n",
            "Epoch 75/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.8483 - accuracy: 0.6382 - val_loss: 1.1224 - val_accuracy: 0.5311\n",
            "Epoch 76/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.8466 - accuracy: 0.6400 - val_loss: 1.1405 - val_accuracy: 0.5294\n",
            "Epoch 77/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.8457 - accuracy: 0.6412 - val_loss: 1.2515 - val_accuracy: 0.5030\n",
            "Epoch 78/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.8432 - accuracy: 0.6410 - val_loss: 1.1354 - val_accuracy: 0.5270\n",
            "Epoch 79/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.8373 - accuracy: 0.6461 - val_loss: 1.1316 - val_accuracy: 0.5253\n",
            "Epoch 80/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.8326 - accuracy: 0.6454 - val_loss: 1.1525 - val_accuracy: 0.5180\n",
            "Epoch 81/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.8332 - accuracy: 0.6466 - val_loss: 1.1459 - val_accuracy: 0.5295\n",
            "Epoch 82/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.8274 - accuracy: 0.6491 - val_loss: 1.1513 - val_accuracy: 0.5240\n",
            "Epoch 83/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.8225 - accuracy: 0.6518 - val_loss: 1.1428 - val_accuracy: 0.5261\n",
            "Epoch 84/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.8270 - accuracy: 0.6497 - val_loss: 1.1588 - val_accuracy: 0.5231\n",
            "Epoch 85/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.8214 - accuracy: 0.6521 - val_loss: 1.1843 - val_accuracy: 0.5209\n",
            "Epoch 86/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.8170 - accuracy: 0.6552 - val_loss: 1.1544 - val_accuracy: 0.5239\n",
            "Epoch 87/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.8117 - accuracy: 0.6584 - val_loss: 1.1628 - val_accuracy: 0.5292\n",
            "Epoch 88/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.8084 - accuracy: 0.6589 - val_loss: 1.1550 - val_accuracy: 0.5308\n",
            "Epoch 89/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.8116 - accuracy: 0.6581 - val_loss: 1.1761 - val_accuracy: 0.5274\n",
            "Epoch 90/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.8055 - accuracy: 0.6592 - val_loss: 1.1664 - val_accuracy: 0.5274\n",
            "Epoch 91/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.8035 - accuracy: 0.6614 - val_loss: 1.1807 - val_accuracy: 0.5196\n",
            "Epoch 92/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.7978 - accuracy: 0.6634 - val_loss: 1.1649 - val_accuracy: 0.5283\n",
            "Epoch 93/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.7982 - accuracy: 0.6638 - val_loss: 1.1656 - val_accuracy: 0.5332\n",
            "Epoch 94/150\n",
            "991/991 [==============================] - 14s 14ms/step - loss: 0.7923 - accuracy: 0.6667 - val_loss: 1.1687 - val_accuracy: 0.5334\n",
            "Epoch 95/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.7908 - accuracy: 0.6671 - val_loss: 1.1650 - val_accuracy: 0.5223\n",
            "Epoch 96/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.7901 - accuracy: 0.6672 - val_loss: 1.1681 - val_accuracy: 0.5270\n",
            "Epoch 97/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.7841 - accuracy: 0.6715 - val_loss: 1.1459 - val_accuracy: 0.5355\n",
            "Epoch 98/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.7798 - accuracy: 0.6727 - val_loss: 1.2106 - val_accuracy: 0.5223\n",
            "Epoch 99/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.7786 - accuracy: 0.6735 - val_loss: 1.1811 - val_accuracy: 0.5312\n",
            "Epoch 100/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.7738 - accuracy: 0.6757 - val_loss: 1.1774 - val_accuracy: 0.5321\n",
            "Epoch 101/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.7709 - accuracy: 0.6742 - val_loss: 1.2033 - val_accuracy: 0.5254\n",
            "Epoch 102/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.7698 - accuracy: 0.6764 - val_loss: 1.1872 - val_accuracy: 0.5254\n",
            "Epoch 103/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.7646 - accuracy: 0.6784 - val_loss: 1.1904 - val_accuracy: 0.5321\n",
            "Epoch 104/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.7626 - accuracy: 0.6806 - val_loss: 1.1790 - val_accuracy: 0.5334\n",
            "Epoch 105/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.7579 - accuracy: 0.6837 - val_loss: 1.1764 - val_accuracy: 0.5325\n",
            "Epoch 106/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.7570 - accuracy: 0.6813 - val_loss: 1.1803 - val_accuracy: 0.5327\n",
            "Epoch 107/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.7559 - accuracy: 0.6833 - val_loss: 1.1584 - val_accuracy: 0.5324\n",
            "Epoch 108/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.7502 - accuracy: 0.6872 - val_loss: 1.1749 - val_accuracy: 0.5355\n",
            "Epoch 109/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.7506 - accuracy: 0.6858 - val_loss: 1.1879 - val_accuracy: 0.5329\n",
            "Epoch 110/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.7437 - accuracy: 0.6885 - val_loss: 1.1659 - val_accuracy: 0.5407\n",
            "Epoch 111/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.7417 - accuracy: 0.6897 - val_loss: 1.1915 - val_accuracy: 0.5342\n",
            "Epoch 112/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.7365 - accuracy: 0.6923 - val_loss: 1.1948 - val_accuracy: 0.5368\n",
            "Epoch 113/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.7367 - accuracy: 0.6924 - val_loss: 1.1915 - val_accuracy: 0.5298\n",
            "Epoch 114/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.7309 - accuracy: 0.6938 - val_loss: 1.2631 - val_accuracy: 0.5315\n",
            "Epoch 115/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.7313 - accuracy: 0.6958 - val_loss: 1.1719 - val_accuracy: 0.5372\n",
            "Epoch 116/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.7261 - accuracy: 0.6960 - val_loss: 1.2322 - val_accuracy: 0.5325\n",
            "Epoch 117/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.7233 - accuracy: 0.6994 - val_loss: 1.1551 - val_accuracy: 0.5436\n",
            "Epoch 118/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.7186 - accuracy: 0.7011 - val_loss: 1.1994 - val_accuracy: 0.5314\n",
            "Epoch 119/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.7160 - accuracy: 0.7029 - val_loss: 1.2011 - val_accuracy: 0.5383\n",
            "Epoch 120/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.7124 - accuracy: 0.7035 - val_loss: 1.2122 - val_accuracy: 0.5395\n",
            "Epoch 121/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.7105 - accuracy: 0.7048 - val_loss: 1.2501 - val_accuracy: 0.5345\n",
            "Epoch 122/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.7090 - accuracy: 0.7068 - val_loss: 1.1758 - val_accuracy: 0.5433\n",
            "Epoch 123/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.7012 - accuracy: 0.7095 - val_loss: 1.2429 - val_accuracy: 0.5353\n",
            "Epoch 124/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.6976 - accuracy: 0.7122 - val_loss: 1.1999 - val_accuracy: 0.5434\n",
            "Epoch 125/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.6987 - accuracy: 0.7100 - val_loss: 1.1949 - val_accuracy: 0.5468\n",
            "Epoch 126/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.6921 - accuracy: 0.7146 - val_loss: 1.2442 - val_accuracy: 0.5339\n",
            "Epoch 127/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.6890 - accuracy: 0.7158 - val_loss: 1.1960 - val_accuracy: 0.5395\n",
            "Epoch 128/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.6886 - accuracy: 0.7146 - val_loss: 1.2624 - val_accuracy: 0.5363\n",
            "Epoch 129/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.6827 - accuracy: 0.7202 - val_loss: 1.2176 - val_accuracy: 0.5419\n",
            "Epoch 130/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.6830 - accuracy: 0.7180 - val_loss: 1.2118 - val_accuracy: 0.5477\n",
            "Epoch 131/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.6762 - accuracy: 0.7232 - val_loss: 1.2170 - val_accuracy: 0.5396\n",
            "Epoch 132/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.6770 - accuracy: 0.7198 - val_loss: 1.1896 - val_accuracy: 0.5398\n",
            "Epoch 133/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.6703 - accuracy: 0.7225 - val_loss: 1.2415 - val_accuracy: 0.5366\n",
            "Epoch 134/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.6688 - accuracy: 0.7247 - val_loss: 1.1961 - val_accuracy: 0.5413\n",
            "Epoch 135/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.6647 - accuracy: 0.7273 - val_loss: 1.2812 - val_accuracy: 0.5331\n",
            "Epoch 136/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.6649 - accuracy: 0.7253 - val_loss: 1.2581 - val_accuracy: 0.5410\n",
            "Epoch 137/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.6635 - accuracy: 0.7276 - val_loss: 1.2365 - val_accuracy: 0.5379\n",
            "Epoch 138/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.6597 - accuracy: 0.7274 - val_loss: 1.2820 - val_accuracy: 0.5405\n",
            "Epoch 139/150\n",
            "991/991 [==============================] - 14s 14ms/step - loss: 0.6572 - accuracy: 0.7308 - val_loss: 1.2638 - val_accuracy: 0.5336\n",
            "Epoch 140/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.6491 - accuracy: 0.7332 - val_loss: 1.2902 - val_accuracy: 0.5439\n",
            "Epoch 141/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.6470 - accuracy: 0.7346 - val_loss: 1.2916 - val_accuracy: 0.5426\n",
            "Epoch 142/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.6438 - accuracy: 0.7379 - val_loss: 1.2097 - val_accuracy: 0.5436\n",
            "Epoch 143/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.6412 - accuracy: 0.7362 - val_loss: 1.2986 - val_accuracy: 0.5427\n",
            "Epoch 144/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.6394 - accuracy: 0.7388 - val_loss: 1.2802 - val_accuracy: 0.5459\n",
            "Epoch 145/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.6405 - accuracy: 0.7383 - val_loss: 1.2938 - val_accuracy: 0.5432\n",
            "Epoch 146/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.6360 - accuracy: 0.7398 - val_loss: 1.3637 - val_accuracy: 0.5369\n",
            "Epoch 147/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.6298 - accuracy: 0.7435 - val_loss: 1.2857 - val_accuracy: 0.5442\n",
            "Epoch 148/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.6303 - accuracy: 0.7431 - val_loss: 1.3014 - val_accuracy: 0.5427\n",
            "Epoch 149/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.6232 - accuracy: 0.7460 - val_loss: 1.2706 - val_accuracy: 0.5406\n",
            "Epoch 150/150\n",
            "991/991 [==============================] - 13s 13ms/step - loss: 0.6189 - accuracy: 0.7466 - val_loss: 1.3010 - val_accuracy: 0.5389\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_CNN_LSTM.evaluate(xTest, yTest)"
      ],
      "metadata": {
        "id": "hF9zqY-RzGz3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a34bc42e-17a4-4be6-c734-7ef14c349b15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2201/2201 [==============================] - 13s 6ms/step - loss: 0.5842 - accuracy: 0.7690\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5841527581214905, 0.7689686417579651]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_CNN_LSTM = model_CNN_LSTM.fit(xTrain, yTrain, epochs=150, batch_size=128, verbose=1, validation_split=0.1)"
      ],
      "metadata": {
        "id": "Qkm9J3DeaXPA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6ff275e-d787-43eb-ec2b-1749f133c700"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.5333 - accuracy: 0.7839 - val_loss: 1.3866 - val_accuracy: 0.5442\n",
            "Epoch 2/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.5306 - accuracy: 0.7840 - val_loss: 1.3849 - val_accuracy: 0.5468\n",
            "Epoch 3/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.5265 - accuracy: 0.7877 - val_loss: 1.4474 - val_accuracy: 0.5464\n",
            "Epoch 4/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.5244 - accuracy: 0.7875 - val_loss: 1.4394 - val_accuracy: 0.5450\n",
            "Epoch 5/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.5220 - accuracy: 0.7878 - val_loss: 1.4234 - val_accuracy: 0.5484\n",
            "Epoch 6/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.5198 - accuracy: 0.7903 - val_loss: 1.4066 - val_accuracy: 0.5480\n",
            "Epoch 7/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.5177 - accuracy: 0.7910 - val_loss: 1.3992 - val_accuracy: 0.5461\n",
            "Epoch 8/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.5161 - accuracy: 0.7906 - val_loss: 1.4494 - val_accuracy: 0.5466\n",
            "Epoch 9/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.5156 - accuracy: 0.7927 - val_loss: 1.4368 - val_accuracy: 0.5493\n",
            "Epoch 10/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.5093 - accuracy: 0.7956 - val_loss: 1.4534 - val_accuracy: 0.5426\n",
            "Epoch 11/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.5090 - accuracy: 0.7941 - val_loss: 1.4628 - val_accuracy: 0.5443\n",
            "Epoch 12/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.4995 - accuracy: 0.7979 - val_loss: 1.5015 - val_accuracy: 0.5497\n",
            "Epoch 13/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.5055 - accuracy: 0.7967 - val_loss: 1.5061 - val_accuracy: 0.5463\n",
            "Epoch 14/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.4972 - accuracy: 0.7998 - val_loss: 1.5303 - val_accuracy: 0.5483\n",
            "Epoch 15/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.4981 - accuracy: 0.7985 - val_loss: 1.5111 - val_accuracy: 0.5389\n",
            "Epoch 16/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.4910 - accuracy: 0.8035 - val_loss: 1.5215 - val_accuracy: 0.5495\n",
            "Epoch 17/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.4928 - accuracy: 0.8024 - val_loss: 1.5340 - val_accuracy: 0.5434\n",
            "Epoch 18/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.4869 - accuracy: 0.8045 - val_loss: 1.5414 - val_accuracy: 0.5459\n",
            "Epoch 19/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.4849 - accuracy: 0.8053 - val_loss: 1.4901 - val_accuracy: 0.5454\n",
            "Epoch 20/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.4788 - accuracy: 0.8075 - val_loss: 1.5385 - val_accuracy: 0.5436\n",
            "Epoch 21/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.4827 - accuracy: 0.8066 - val_loss: 1.5066 - val_accuracy: 0.5477\n",
            "Epoch 22/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.4763 - accuracy: 0.8082 - val_loss: 1.5296 - val_accuracy: 0.5429\n",
            "Epoch 23/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.4761 - accuracy: 0.8102 - val_loss: 1.5527 - val_accuracy: 0.5480\n",
            "Epoch 24/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.4736 - accuracy: 0.8109 - val_loss: 1.5840 - val_accuracy: 0.5385\n",
            "Epoch 25/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.4695 - accuracy: 0.8122 - val_loss: 1.5354 - val_accuracy: 0.5449\n",
            "Epoch 26/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.4698 - accuracy: 0.8122 - val_loss: 1.5414 - val_accuracy: 0.5460\n",
            "Epoch 27/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.4637 - accuracy: 0.8157 - val_loss: 1.5919 - val_accuracy: 0.5470\n",
            "Epoch 28/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.4634 - accuracy: 0.8147 - val_loss: 1.5866 - val_accuracy: 0.5453\n",
            "Epoch 29/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.4590 - accuracy: 0.8167 - val_loss: 1.5836 - val_accuracy: 0.5386\n",
            "Epoch 30/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.4585 - accuracy: 0.8162 - val_loss: 1.5447 - val_accuracy: 0.5420\n",
            "Epoch 31/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.4571 - accuracy: 0.8184 - val_loss: 1.6510 - val_accuracy: 0.5483\n",
            "Epoch 32/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.4470 - accuracy: 0.8235 - val_loss: 1.5993 - val_accuracy: 0.5460\n",
            "Epoch 33/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.4531 - accuracy: 0.8190 - val_loss: 1.6274 - val_accuracy: 0.5450\n",
            "Epoch 34/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.4446 - accuracy: 0.8229 - val_loss: 1.6582 - val_accuracy: 0.5480\n",
            "Epoch 35/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.4410 - accuracy: 0.8250 - val_loss: 1.5929 - val_accuracy: 0.5463\n",
            "Epoch 36/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.4445 - accuracy: 0.8250 - val_loss: 1.6904 - val_accuracy: 0.5456\n",
            "Epoch 37/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.4388 - accuracy: 0.8260 - val_loss: 1.6371 - val_accuracy: 0.5439\n",
            "Epoch 38/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.4354 - accuracy: 0.8271 - val_loss: 1.6915 - val_accuracy: 0.5466\n",
            "Epoch 39/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.4307 - accuracy: 0.8296 - val_loss: 1.6954 - val_accuracy: 0.5456\n",
            "Epoch 40/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.4304 - accuracy: 0.8294 - val_loss: 1.6359 - val_accuracy: 0.5413\n",
            "Epoch 41/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.4290 - accuracy: 0.8300 - val_loss: 1.6548 - val_accuracy: 0.5521\n",
            "Epoch 42/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.4292 - accuracy: 0.8286 - val_loss: 1.6887 - val_accuracy: 0.5432\n",
            "Epoch 43/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.4233 - accuracy: 0.8341 - val_loss: 1.7172 - val_accuracy: 0.5443\n",
            "Epoch 44/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.4211 - accuracy: 0.8320 - val_loss: 1.7175 - val_accuracy: 0.5433\n",
            "Epoch 45/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.4187 - accuracy: 0.8334 - val_loss: 1.6517 - val_accuracy: 0.5457\n",
            "Epoch 46/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.4188 - accuracy: 0.8349 - val_loss: 1.6859 - val_accuracy: 0.5480\n",
            "Epoch 47/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.4156 - accuracy: 0.8348 - val_loss: 1.6965 - val_accuracy: 0.5494\n",
            "Epoch 48/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.4137 - accuracy: 0.8358 - val_loss: 1.7552 - val_accuracy: 0.5413\n",
            "Epoch 49/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.4069 - accuracy: 0.8393 - val_loss: 1.7532 - val_accuracy: 0.5373\n",
            "Epoch 50/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.4095 - accuracy: 0.8377 - val_loss: 1.7683 - val_accuracy: 0.5501\n",
            "Epoch 51/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.4083 - accuracy: 0.8396 - val_loss: 1.6993 - val_accuracy: 0.5416\n",
            "Epoch 52/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.4042 - accuracy: 0.8395 - val_loss: 1.7173 - val_accuracy: 0.5500\n",
            "Epoch 53/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.3979 - accuracy: 0.8436 - val_loss: 1.7624 - val_accuracy: 0.5454\n",
            "Epoch 54/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.3996 - accuracy: 0.8421 - val_loss: 1.7772 - val_accuracy: 0.5478\n",
            "Epoch 55/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.3961 - accuracy: 0.8443 - val_loss: 1.7785 - val_accuracy: 0.5412\n",
            "Epoch 56/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.3932 - accuracy: 0.8452 - val_loss: 1.7624 - val_accuracy: 0.5420\n",
            "Epoch 57/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.3940 - accuracy: 0.8458 - val_loss: 1.6956 - val_accuracy: 0.5456\n",
            "Epoch 58/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.3905 - accuracy: 0.8463 - val_loss: 1.7161 - val_accuracy: 0.5433\n",
            "Epoch 59/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.3868 - accuracy: 0.8474 - val_loss: 1.7733 - val_accuracy: 0.5395\n",
            "Epoch 60/150\n",
            "496/496 [==============================] - 8s 16ms/step - loss: 0.3860 - accuracy: 0.8480 - val_loss: 1.7659 - val_accuracy: 0.5396\n",
            "Epoch 61/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.3842 - accuracy: 0.8489 - val_loss: 1.7580 - val_accuracy: 0.5447\n",
            "Epoch 62/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.3820 - accuracy: 0.8497 - val_loss: 1.7434 - val_accuracy: 0.5500\n",
            "Epoch 63/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.3764 - accuracy: 0.8511 - val_loss: 1.8244 - val_accuracy: 0.5453\n",
            "Epoch 64/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.3828 - accuracy: 0.8505 - val_loss: 1.7799 - val_accuracy: 0.5453\n",
            "Epoch 65/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.3756 - accuracy: 0.8534 - val_loss: 1.7925 - val_accuracy: 0.5460\n",
            "Epoch 66/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.3716 - accuracy: 0.8547 - val_loss: 1.7588 - val_accuracy: 0.5453\n",
            "Epoch 67/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.3710 - accuracy: 0.8545 - val_loss: 1.8532 - val_accuracy: 0.5463\n",
            "Epoch 68/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.3720 - accuracy: 0.8556 - val_loss: 1.8641 - val_accuracy: 0.5451\n",
            "Epoch 69/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.3710 - accuracy: 0.8555 - val_loss: 1.8050 - val_accuracy: 0.5442\n",
            "Epoch 70/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.3605 - accuracy: 0.8581 - val_loss: 1.8373 - val_accuracy: 0.5470\n",
            "Epoch 71/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.3644 - accuracy: 0.8588 - val_loss: 1.8344 - val_accuracy: 0.5436\n",
            "Epoch 72/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.3618 - accuracy: 0.8587 - val_loss: 1.8289 - val_accuracy: 0.5453\n",
            "Epoch 73/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.3575 - accuracy: 0.8616 - val_loss: 1.8615 - val_accuracy: 0.5464\n",
            "Epoch 74/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.3594 - accuracy: 0.8606 - val_loss: 1.8480 - val_accuracy: 0.5480\n",
            "Epoch 75/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.3529 - accuracy: 0.8637 - val_loss: 1.8586 - val_accuracy: 0.5439\n",
            "Epoch 76/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.3581 - accuracy: 0.8607 - val_loss: 1.8922 - val_accuracy: 0.5457\n",
            "Epoch 77/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.3530 - accuracy: 0.8644 - val_loss: 1.8260 - val_accuracy: 0.5443\n",
            "Epoch 78/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.3488 - accuracy: 0.8650 - val_loss: 1.8721 - val_accuracy: 0.5461\n",
            "Epoch 79/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.3440 - accuracy: 0.8667 - val_loss: 1.9300 - val_accuracy: 0.5473\n",
            "Epoch 80/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.3474 - accuracy: 0.8652 - val_loss: 1.8547 - val_accuracy: 0.5437\n",
            "Epoch 81/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.3413 - accuracy: 0.8677 - val_loss: 1.9137 - val_accuracy: 0.5451\n",
            "Epoch 82/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.3421 - accuracy: 0.8678 - val_loss: 1.9171 - val_accuracy: 0.5426\n",
            "Epoch 83/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.3447 - accuracy: 0.8669 - val_loss: 1.9211 - val_accuracy: 0.5468\n",
            "Epoch 84/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.3386 - accuracy: 0.8698 - val_loss: 1.8794 - val_accuracy: 0.5463\n",
            "Epoch 85/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.3360 - accuracy: 0.8708 - val_loss: 1.9231 - val_accuracy: 0.5467\n",
            "Epoch 86/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.3341 - accuracy: 0.8703 - val_loss: 1.9742 - val_accuracy: 0.5446\n",
            "Epoch 87/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.3282 - accuracy: 0.8740 - val_loss: 1.9441 - val_accuracy: 0.5449\n",
            "Epoch 88/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.3264 - accuracy: 0.8747 - val_loss: 2.0018 - val_accuracy: 0.5402\n",
            "Epoch 89/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.3296 - accuracy: 0.8734 - val_loss: 1.9763 - val_accuracy: 0.5429\n",
            "Epoch 90/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.3260 - accuracy: 0.8754 - val_loss: 1.9091 - val_accuracy: 0.5403\n",
            "Epoch 91/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.3238 - accuracy: 0.8754 - val_loss: 1.9387 - val_accuracy: 0.5444\n",
            "Epoch 92/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.3228 - accuracy: 0.8776 - val_loss: 1.9932 - val_accuracy: 0.5426\n",
            "Epoch 93/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.3226 - accuracy: 0.8768 - val_loss: 1.9767 - val_accuracy: 0.5426\n",
            "Epoch 94/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.3144 - accuracy: 0.8809 - val_loss: 2.0692 - val_accuracy: 0.5436\n",
            "Epoch 95/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.3188 - accuracy: 0.8768 - val_loss: 1.9838 - val_accuracy: 0.5478\n",
            "Epoch 96/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.3134 - accuracy: 0.8798 - val_loss: 2.0128 - val_accuracy: 0.5432\n",
            "Epoch 97/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.3120 - accuracy: 0.8808 - val_loss: 1.9574 - val_accuracy: 0.5417\n",
            "Epoch 98/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.3126 - accuracy: 0.8806 - val_loss: 2.0115 - val_accuracy: 0.5415\n",
            "Epoch 99/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.3094 - accuracy: 0.8817 - val_loss: 2.0063 - val_accuracy: 0.5468\n",
            "Epoch 100/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.3030 - accuracy: 0.8844 - val_loss: 2.0573 - val_accuracy: 0.5439\n",
            "Epoch 101/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.3065 - accuracy: 0.8843 - val_loss: 2.0038 - val_accuracy: 0.5468\n",
            "Epoch 102/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.3056 - accuracy: 0.8842 - val_loss: 1.9673 - val_accuracy: 0.5424\n",
            "Epoch 103/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.3035 - accuracy: 0.8836 - val_loss: 2.0017 - val_accuracy: 0.5461\n",
            "Epoch 104/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.3027 - accuracy: 0.8843 - val_loss: 2.0102 - val_accuracy: 0.5346\n",
            "Epoch 105/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.2976 - accuracy: 0.8878 - val_loss: 1.9982 - val_accuracy: 0.5365\n",
            "Epoch 106/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.2939 - accuracy: 0.8887 - val_loss: 2.0384 - val_accuracy: 0.5420\n",
            "Epoch 107/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.2979 - accuracy: 0.8870 - val_loss: 2.1366 - val_accuracy: 0.5422\n",
            "Epoch 108/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.2923 - accuracy: 0.8894 - val_loss: 2.1241 - val_accuracy: 0.5410\n",
            "Epoch 109/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.2920 - accuracy: 0.8904 - val_loss: 2.0689 - val_accuracy: 0.5464\n",
            "Epoch 110/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.2908 - accuracy: 0.8903 - val_loss: 2.0221 - val_accuracy: 0.5470\n",
            "Epoch 111/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.2881 - accuracy: 0.8914 - val_loss: 2.0650 - val_accuracy: 0.5459\n",
            "Epoch 112/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.2867 - accuracy: 0.8904 - val_loss: 2.0937 - val_accuracy: 0.5466\n",
            "Epoch 113/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.2825 - accuracy: 0.8931 - val_loss: 2.0665 - val_accuracy: 0.5429\n",
            "Epoch 114/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.2827 - accuracy: 0.8933 - val_loss: 2.0817 - val_accuracy: 0.5426\n",
            "Epoch 115/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.2832 - accuracy: 0.8932 - val_loss: 2.0091 - val_accuracy: 0.5434\n",
            "Epoch 116/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.2789 - accuracy: 0.8947 - val_loss: 2.0998 - val_accuracy: 0.5456\n",
            "Epoch 117/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.2810 - accuracy: 0.8940 - val_loss: 2.0611 - val_accuracy: 0.5399\n",
            "Epoch 118/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.2730 - accuracy: 0.8973 - val_loss: 2.1759 - val_accuracy: 0.5420\n",
            "Epoch 119/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.2725 - accuracy: 0.8982 - val_loss: 2.0928 - val_accuracy: 0.5503\n",
            "Epoch 120/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.2734 - accuracy: 0.8978 - val_loss: 2.1141 - val_accuracy: 0.5432\n",
            "Epoch 121/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.2689 - accuracy: 0.8994 - val_loss: 2.1259 - val_accuracy: 0.5400\n",
            "Epoch 122/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.2663 - accuracy: 0.9006 - val_loss: 2.2060 - val_accuracy: 0.5498\n",
            "Epoch 123/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.2689 - accuracy: 0.8993 - val_loss: 2.1059 - val_accuracy: 0.5471\n",
            "Epoch 124/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.2668 - accuracy: 0.9011 - val_loss: 2.2013 - val_accuracy: 0.5405\n",
            "Epoch 125/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.2656 - accuracy: 0.9005 - val_loss: 2.1884 - val_accuracy: 0.5362\n",
            "Epoch 126/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.2619 - accuracy: 0.9018 - val_loss: 2.0938 - val_accuracy: 0.5398\n",
            "Epoch 127/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.2576 - accuracy: 0.9030 - val_loss: 2.1946 - val_accuracy: 0.5409\n",
            "Epoch 128/150\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 0.2591 - accuracy: 0.9034 - val_loss: 2.1532 - val_accuracy: 0.5393\n",
            "Epoch 129/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.2582 - accuracy: 0.9051 - val_loss: 2.1342 - val_accuracy: 0.5430\n",
            "Epoch 130/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.2585 - accuracy: 0.9036 - val_loss: 2.2021 - val_accuracy: 0.5332\n",
            "Epoch 131/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.2551 - accuracy: 0.9055 - val_loss: 2.0765 - val_accuracy: 0.5436\n",
            "Epoch 132/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.2496 - accuracy: 0.9077 - val_loss: 2.1183 - val_accuracy: 0.5417\n",
            "Epoch 133/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.2434 - accuracy: 0.9093 - val_loss: 2.2336 - val_accuracy: 0.5440\n",
            "Epoch 134/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.2496 - accuracy: 0.9059 - val_loss: 2.2365 - val_accuracy: 0.5412\n",
            "Epoch 135/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.2503 - accuracy: 0.9075 - val_loss: 2.1711 - val_accuracy: 0.5424\n",
            "Epoch 136/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.2447 - accuracy: 0.9088 - val_loss: 2.1961 - val_accuracy: 0.5432\n",
            "Epoch 137/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.2407 - accuracy: 0.9115 - val_loss: 2.2334 - val_accuracy: 0.5422\n",
            "Epoch 138/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.2378 - accuracy: 0.9117 - val_loss: 2.2261 - val_accuracy: 0.5344\n",
            "Epoch 139/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.2393 - accuracy: 0.9115 - val_loss: 2.1360 - val_accuracy: 0.5402\n",
            "Epoch 140/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.2419 - accuracy: 0.9109 - val_loss: 2.1617 - val_accuracy: 0.5409\n",
            "Epoch 141/150\n",
            "496/496 [==============================] - 8s 16ms/step - loss: 0.2386 - accuracy: 0.9115 - val_loss: 2.2124 - val_accuracy: 0.5478\n",
            "Epoch 142/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.2396 - accuracy: 0.9116 - val_loss: 2.2541 - val_accuracy: 0.5409\n",
            "Epoch 143/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.2382 - accuracy: 0.9127 - val_loss: 2.2251 - val_accuracy: 0.5432\n",
            "Epoch 144/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.2350 - accuracy: 0.9139 - val_loss: 2.1606 - val_accuracy: 0.5457\n",
            "Epoch 145/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.2295 - accuracy: 0.9151 - val_loss: 2.2630 - val_accuracy: 0.5477\n",
            "Epoch 146/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.2285 - accuracy: 0.9155 - val_loss: 2.2560 - val_accuracy: 0.5468\n",
            "Epoch 147/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.2290 - accuracy: 0.9164 - val_loss: 2.3486 - val_accuracy: 0.5371\n",
            "Epoch 148/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.2284 - accuracy: 0.9165 - val_loss: 2.2198 - val_accuracy: 0.5407\n",
            "Epoch 149/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.2213 - accuracy: 0.9183 - val_loss: 2.3115 - val_accuracy: 0.5376\n",
            "Epoch 150/150\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 0.2271 - accuracy: 0.9173 - val_loss: 2.1750 - val_accuracy: 0.5399\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_CNN_LSTM.evaluate(xTest, yTest)"
      ],
      "metadata": {
        "id": "5a9nbp5gcNuf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6e55824-37eb-4915-a7c5-cae771ae4ad3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2201/2201 [==============================] - 13s 6ms/step - loss: 0.3593 - accuracy: 0.9017\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.35933899879455566, 0.9016640186309814]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop"
      ],
      "metadata": {
        "id": "vvfSuIwSRtZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zyQLSJK1Ru61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n"
      ],
      "metadata": {
        "id": "SoSvgIVvewJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_CNN_LSTM.save('/content/drive/My Drive/temp/model_CNN_LSTM_tanh_final.h5')"
      ],
      "metadata": {
        "id": "UgJ6CxZMC-_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_CNN_LSTM = load_model('/content/drive/My Drive/temp/model_CNN_LSTM_tanh_final.h5')"
      ],
      "metadata": {
        "id": "ovNMkMm12SNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#загрузим 1 датасет, на котором сеть не обучалась\n",
        "sub1_97_file = '/content/drive/My Drive/temp/fnirs_dataset test/sub_97.csv'\n",
        "df_test = pd.read_csv(sub1_97_file)\n",
        "xLen = 6\n",
        "xTest97, yTest97 = drop_dataset(df_test, xLen)"
      ],
      "metadata": {
        "id": "df3TDEgVv8x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_CNN_LSTM.evaluate(xTest97, yTest97)"
      ],
      "metadata": {
        "id": "ZyMQcHFuwnJ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bd28bf1-bd6c-4355-a75a-2972deaf593a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36/36 [==============================] - 0s 8ms/step - loss: 4.1268 - accuracy: 0.2324\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4.1267876625061035, 0.23239436745643616]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xTest97.shape, yTest97.shape"
      ],
      "metadata": {
        "id": "YmawhmJO2jN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробуем дообучить модель на 97ом испытуемом\n",
        "Для этого разобьем датасет на обучающую и тестовую выборку"
      ],
      "metadata": {
        "id": "b4KAF6EP2ou-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xTest97[0].shape"
      ],
      "metadata": {
        "id": "hQh4ZInp2m3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xTrain97 = xTest97[0:int(len(xTest97)*0.9)]\n",
        "xVal97 = xTest97[int(len(xTest97)*0.9 + 1):]\n",
        "\n",
        "yTrain97 = yTest97[0:int(len(yTest97)*0.9)]\n",
        "yVal97 = yTest97[int(len(yTest97)*0.9 + 1):]\n",
        "\n",
        "xTrain97.shape, xVal97.shape, yTrain97.shape, yVal97.shape, len(xTest97)"
      ],
      "metadata": {
        "id": "-8Vu-h3X4dh5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25972653-b747-416a-a90c-4fa3aef05044"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1022, 6, 8), (113, 6, 8), (1022, 4), (113, 4), 1136)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history97 = model_CNN_LSTM.fit(xTrain97, yTrain97, epochs=50, batch_size=64, verbose=1)"
      ],
      "metadata": {
        "id": "NK9rF0mW3_b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "512dc3c2-1756-448d-835d-d63f281b4836"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "16/16 [==============================] - 0s 16ms/step - loss: 2.8244 - accuracy: 0.3659\n",
            "Epoch 2/50\n",
            "16/16 [==============================] - 0s 14ms/step - loss: 1.0626 - accuracy: 0.5626\n",
            "Epoch 3/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.7774 - accuracy: 0.6712\n",
            "Epoch 4/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.6566 - accuracy: 0.7329\n",
            "Epoch 5/50\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.5972 - accuracy: 0.7554\n",
            "Epoch 6/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.5216 - accuracy: 0.7769\n",
            "Epoch 7/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4830 - accuracy: 0.8102\n",
            "Epoch 8/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.4246 - accuracy: 0.8190\n",
            "Epoch 9/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3803 - accuracy: 0.8474\n",
            "Epoch 10/50\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.3418 - accuracy: 0.8728\n",
            "Epoch 11/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3290 - accuracy: 0.8728\n",
            "Epoch 12/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.3167 - accuracy: 0.8885\n",
            "Epoch 13/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2824 - accuracy: 0.9012\n",
            "Epoch 14/50\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2316 - accuracy: 0.9207\n",
            "Epoch 15/50\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.2215 - accuracy: 0.9149\n",
            "Epoch 16/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.2040 - accuracy: 0.9276\n",
            "Epoch 17/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1814 - accuracy: 0.9393\n",
            "Epoch 18/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1590 - accuracy: 0.9462\n",
            "Epoch 19/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1496 - accuracy: 0.9521\n",
            "Epoch 20/50\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.1216 - accuracy: 0.9599\n",
            "Epoch 21/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1182 - accuracy: 0.9638\n",
            "Epoch 22/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.1324 - accuracy: 0.9579\n",
            "Epoch 23/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0971 - accuracy: 0.9726\n",
            "Epoch 24/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0947 - accuracy: 0.9736\n",
            "Epoch 25/50\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0739 - accuracy: 0.9765\n",
            "Epoch 26/50\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0698 - accuracy: 0.9804\n",
            "Epoch 27/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0872 - accuracy: 0.9716\n",
            "Epoch 28/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0640 - accuracy: 0.9873\n",
            "Epoch 29/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0603 - accuracy: 0.9834\n",
            "Epoch 30/50\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0604 - accuracy: 0.9853\n",
            "Epoch 31/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0577 - accuracy: 0.9843\n",
            "Epoch 32/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0600 - accuracy: 0.9853\n",
            "Epoch 33/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0503 - accuracy: 0.9873\n",
            "Epoch 34/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0549 - accuracy: 0.9863\n",
            "Epoch 35/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0418 - accuracy: 0.9883\n",
            "Epoch 36/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0432 - accuracy: 0.9883\n",
            "Epoch 37/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0357 - accuracy: 0.9892\n",
            "Epoch 38/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0449 - accuracy: 0.9892\n",
            "Epoch 39/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0329 - accuracy: 0.9912\n",
            "Epoch 40/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0214 - accuracy: 0.9971\n",
            "Epoch 41/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0281 - accuracy: 0.9941\n",
            "Epoch 42/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0309 - accuracy: 0.9902\n",
            "Epoch 43/50\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0234 - accuracy: 0.9951\n",
            "Epoch 44/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0262 - accuracy: 0.9941\n",
            "Epoch 45/50\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0369 - accuracy: 0.9863\n",
            "Epoch 46/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0172 - accuracy: 0.9971\n",
            "Epoch 47/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0245 - accuracy: 0.9932\n",
            "Epoch 48/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0129 - accuracy: 0.9971\n",
            "Epoch 49/50\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 0.0263 - accuracy: 0.9932\n",
            "Epoch 50/50\n",
            "16/16 [==============================] - 0s 13ms/step - loss: 0.0298 - accuracy: 0.9912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1,2, figsize=(14, 7))\n",
        "axs[0].plot(history97.history['loss'], \n",
        "         label='Средняя абсолютная ошибка на обучающем наборе')\n",
        "axs[0].legend()\n",
        "\n",
        "axs[1].plot(history97.history['accuracy'], \n",
        "         label='Средняя абсолютная точность на обучающем наборе')\n",
        "axs[1].legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qxdaNHtJ_3fE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "eef17e15-1d00-4044-9096-0af7285ff3f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1008x504 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_CNN_LSTM.evaluate(xVal97, yVal97)"
      ],
      "metadata": {
        "id": "WdsCkAZL62a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae29c182-a3c8-4490-81b2-6a2bdc6a0068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2614 - accuracy: 0.9381\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.26138007640838623, 0.9380530714988708]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrt8vQiv/pxCHWPJJpcZKM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}